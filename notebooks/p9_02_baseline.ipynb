{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6858949f-b715-4a15-b43c-482420237925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATASET_DIR = os.getenv(\"DATASET_DIR\", \"/workspace/data\")\n",
    "CONFIG_DIR = os.getenv(\"CONFIG_DIR\", \"/workspace/configs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b25021b-2a44-4b6c-b14f-6d3216a6d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from p9dg.histo_dataset import HistoDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b6f415-b6ae-4162-a334-8fff48bc06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 1Ô∏è‚É£ Config\n",
    "# ------------------------------\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.makedirs(\"artifacts\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8deae575-680d-4085-bfb7-96c412247646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® R√©f√©rence Vahadane fix√©e : TUM-RQEVGAED.tif\n",
      "üé® R√©f√©rence Vahadane auto: TUM-RQEVGAED.tif\n",
      "‚úÖ Seuils par classe charg√©s depuis : /workspace/configs/seuils_par_classe.json\n",
      "üé® R√©f√©rence Vahadane fix√©e : TUM-TCGA-TWCEHKLC.tif\n",
      "üé® R√©f√©rence Vahadane auto: TUM-TCGA-TWCEHKLC.tif\n",
      "‚úÖ Seuils par classe charg√©s depuis : /workspace/configs/seuils_par_classe.json\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 2Ô∏è‚É£ Dataset & DataLoader\n",
    "# ------------------------------\n",
    "train_ds = HistoDataset(\n",
    "    root_data=\"/workspace/data\",\n",
    "    split=\"train\",\n",
    "    output_size=256, # taille initiale 244 !\n",
    "    pixel_range=\"imagenet\",\n",
    "    balance_per_class=True, # ‚úÖ essentiel pour l'√©chantillonage\n",
    "    thresholds_json_path=\"configs/seuils_par_classe.json\",\n",
    "    vahadane_enable=True,\n",
    "    vahadane_device=DEVICE,\n",
    "    samples_per_class_per_epoch=200 # 200 (raisonnable)\n",
    ")\n",
    "\n",
    "val_ds = HistoDataset(\n",
    "    root_data=\"/workspace/data\",\n",
    "    split=\"val\",\n",
    "    output_size=256,\n",
    "    pixel_range=\"imagenet\",\n",
    "    balance_per_class=True,\n",
    "    thresholds_json_path=\"configs/seuils_par_classe.json\",\n",
    "    vahadane_enable=True,\n",
    "    vahadane_device=DEVICE,\n",
    "    samples_per_class_per_epoch=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6d889f8-5a52-4b4b-a1da-c57f7db17340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1800 images\n",
      "Val set size: 450 images\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set size: {len(train_ds)} images\")\n",
    "print(f\"Val set size: {len(val_ds)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975db8ef-ff5b-46da-9feb-15b98b470f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Comptage des classes dans le dataset d'entra√Ænement\n",
    "# cls_counts = Counter([y for _, y, _ in [train_ds[i] for i in range(len(train_ds))]])\n",
    "# cls_names = [train_ds.idx_to_class[c] for c in cls_counts.keys()]\n",
    "# cls_values = list(cls_counts.values())\n",
    "\n",
    "# print(f\"üß© Nombre total d'images dans train_ds : {len(train_ds)}\")\n",
    "# for name, count in zip(cls_names, cls_values):\n",
    "#     print(f\"  - {name}: {count}\")\n",
    "\n",
    "# # Petit histogramme\n",
    "# plt.figure(figsize=(6,3))\n",
    "# plt.bar(cls_names, cls_values, color=\"cornflowerblue\")\n",
    "# plt.title(\"Distribution des classes (train)\")\n",
    "# plt.xticks(rotation=45, ha=\"right\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd5d4291-9658-416e-a11e-9ac88374cc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Nombre de classes : 9\n",
      "‚úÖ Mod√®le mobilenetv2 initialis√© sur cuda\n"
     ]
    }
   ],
   "source": [
    "# S√©lection du mod√®le : \"mobilenetv2\" ou \"resnet18\"\n",
    "MODEL_NAME = \"mobilenetv2\"  # ‚Üê par d√©faut\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "num_classes = len(train_ds.class_to_idx)\n",
    "print(f\"üß† Nombre de classes : {num_classes}\")\n",
    "\n",
    "if MODEL_NAME == \"mobilenetv2\":\n",
    "    model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
    "    model.classifier[1] = nn.Linear(model.last_channel, num_classes)\n",
    "elif MODEL_NAME == \"resnet18\":\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "else:\n",
    "    raise ValueError(\"Mod√®le non reconnu\")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "print(f\"‚úÖ Mod√®le {MODEL_NAME} initialis√© sur {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb8f9626-3ef2-476b-83e6-fed9e7883dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Dataloaders pr√™ts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Pr√©paration de l'entrainement\n",
    "# Hyperparam√®tres\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "LR = 1e-3\n",
    "PATIENCE = 6  # early stopping\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True) # pin_memory transfer plus rapide vers GPU\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5,\n",
    "    patience=2, threshold=1e-3, cooldown=1, verbose=True\n",
    ")\n",
    "\n",
    "print(\"üß© Dataloaders pr√™ts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f053e00-adab-4bc8-a033-d99de5c97f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vidage RAM GPU\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe1a3a-9e07-4045-a756-2dff8afd2949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Cache GPU vid√©\n",
      "\n",
      "=== Epoch 1/30 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                                                         | 27/113 [02:34<07:56,  5.54s/it]"
     ]
    }
   ],
   "source": [
    "# Boucle d'entra√Ænement\n",
    "# Adapt√©e pour les petits jeux de donn√©es :\n",
    "# ‚úÖ validation liss√©e (EMA) pour r√©duire les sauts al√©atoires,\n",
    "# ‚úÖ early stopping plus stable (warm-up + min_delta + patience √©tendue),\n",
    "# ‚úÖ scheduler avec seuil et cooldown pour √©viter les r√©ductions de LR pr√©matur√©es,\n",
    "# ‚úÖ gradient clipping pour stabiliser les phases de descente.\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "# ---- Hyperparam√®tres early stopping & stabilit√© ----\n",
    "WARMUP_EPOCHS = 3          # pas d'ES avant ce nombre d'√©poques\n",
    "ES_PATIENCE   = 6          # nombre d'√©poques sans am√©lioration avant arr√™t\n",
    "ES_MIN_DELTA  = 1e-3       # am√©lioration minimale pour reset patience\n",
    "best_val_ema  = float(\"inf\")\n",
    "patience_counter = 0\n",
    "val_ema = None             # moyenne mobile de la val_loss\n",
    "DELTA_POS_PATIENCE = 2\n",
    "delta_pos_counter = 0\n",
    "\n",
    "# ---- Lissage EMA ----\n",
    "def ema(prev, new, alpha=0.3):\n",
    "    return new if prev is None else (alpha * new + (1 - alpha) * prev)\n",
    "\n",
    "# ---- Boucle d'entra√Ænement ----\n",
    "train_losses, val_losses = [], []\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    if epoch % 10 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"üßπ Cache GPU vid√©\")\n",
    "    train_ds.set_epoch(epoch)\n",
    "    print(f\"\\n=== Epoch {epoch+1}/{EPOCHS} ===\")\n",
    "\n",
    "    # ---- TRAIN ----\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for imgs, labels, _ in tqdm(train_loader, desc=\"Train\", leave=False):\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backprop + clipping + update\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_ds)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # ---- VALIDATION ----\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, _ in tqdm(val_loader, desc=\"Val\", leave=False):\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # ---- Lissage & scheduler ----\n",
    "    val_ema = ema(val_ema, val_loss, alpha=0.3)\n",
    "    scheduler.step(val_ema)  # scheduler bas√© sur la perte liss√©e\n",
    "\n",
    "    # ---- Affichage r√©sum√© ----\n",
    "    delta_raw = val_loss - train_loss\n",
    "    delta_ema = val_ema - train_loss\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"LR: {current_lr:.2e}\")\n",
    "    print(f\"üìä Epoch {epoch+1:02d}/{EPOCHS} | \"\n",
    "          f\"Train: {train_loss:.4f} | Val: {val_loss:.4f} | \"\n",
    "          f\"Val(EMA): {val_ema:.4f} | Œîraw={delta_raw:+.4f} | Œîema={delta_ema:+.4f}\")\n",
    "\n",
    "    # --- Surapprentissage : contr√¥le du delta positif ---\n",
    "    if delta_ema > 0:\n",
    "        delta_pos_counter += 1\n",
    "        if delta_pos_counter >= DELTA_POS_PATIENCE:\n",
    "            print(f\"‚ö†Ô∏è Œîema > 0 sur {DELTA_POS_PATIENCE} √©poques cons√©cutives ‚Üí arr√™t pour surapprentissage.\")\n",
    "            break\n",
    "    else:\n",
    "        delta_pos_counter = 0\n",
    "\n",
    "\n",
    "    # ---- Early Stopping (avec warmup & min_delta) ----\n",
    "    if epoch + 1 <= WARMUP_EPOCHS:\n",
    "        improved = False  # on attend avant de juger\n",
    "    else:\n",
    "        improved = (best_val_ema - val_ema) > ES_MIN_DELTA\n",
    "\n",
    "    if improved:\n",
    "        best_val_ema = val_ema\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), f\"artifacts/{MODEL_NAME}_best.pt\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= ES_PATIENCE:\n",
    "            print(\"‚è∏Ô∏è Early stopping d√©clench√© (EMA).\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afeab12-0933-4550-aa8a-92f00262cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(train_losses, label=\"Train\", marker=\"o\")\n",
    "plt.plot(val_losses, label=\"Validation\", marker=\"s\")\n",
    "plt.title(f\"Courbe de perte ({MODEL_NAME})\")\n",
    "plt.xlabel(\"√âpochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88be6c-a4ec-4bde-920c-9ae1dba22e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1Ô∏è‚É£ Chargement du meilleur mod√®le\n",
    "best_path = f\"artifacts/{MODEL_NAME}_best.pt\"\n",
    "state_dict = torch.load(best_path, map_location=DEVICE, weights_only=True)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "print(f\"‚úÖ Meilleur mod√®le charg√© depuis : {best_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2338a6-abec-4671-b91e-4b1ec1e5e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Ô∏è‚É£ Pr√©diction sur le jeu de validation\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels, _ in tqdm(val_loader, desc=\"√âvaluation finale\"):\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(imgs)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d60968-784e-4ee5-90f2-e8f03884f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Ô∏è‚É£ Rapport de classification (macro-F1, recall, pr√©cision)\n",
    "classes = list(train_ds.class_to_idx.keys())\n",
    "\n",
    "print(\"\\n=== Rapport de classification ===\")\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    target_names=classes,\n",
    "    digits=3,\n",
    "    zero_division=0\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f7a35f-8a18-4b5b-9aa7-1040b23e96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4Ô∏è‚É£ Matrice de confusion normalis√©e\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Matrice de confusion (valeurs absolues)\n",
    "cm = confusion_matrix(y_true, y_pred)  # üëà pas de normalize ici\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "    xticklabels=classes, yticklabels=classes\n",
    ")\n",
    "plt.xlabel(\"Pr√©dit\")\n",
    "plt.ylabel(\"R√©el\")\n",
    "plt.title(f\"Matrice de confusion (effectifs absolus) ‚Äî {MODEL_NAME}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b34ae5-4ca0-426b-b53f-f9378be9275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5Ô∏è‚É£ Sauvegarde automatique des r√©sultats\n",
    "plt.savefig(f\"artifacts/confusion_matrix_{MODEL_NAME}.png\")\n",
    "\n",
    "# Sauvegarde du rapport texte\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(\n",
    "    y_true, y_pred,\n",
    "    target_names=classes,\n",
    "    digits=3,\n",
    "    zero_division=0\n",
    ")\n",
    "Path(\"artifacts\").mkdir(exist_ok=True)\n",
    "(Path(\"artifacts\") / f\"classification_report_{MODEL_NAME}.txt\").write_text(report)\n",
    "print(\"üìÅ R√©sultats enregistr√©s dans artifacts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4a69c2-30a0-459e-af6f-cf129e7311ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
